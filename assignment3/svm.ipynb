{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../libs')  # Update this path according to the location of your 'dataset' module\n",
    "import dataset\n",
    "import preprocessing\n",
    "import classes\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen Hyper Params\n",
    "chosen_pca_components = 15\n",
    "chosen_svm_cost = 10\n",
    "chosen_svm_kernel = \"rbf\"\n",
    "chosen_scaler_q = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data()\n",
    "y = np.array(list(map(classes.label_to_class, dataset.labels_array())))\n",
    "\n",
    "X = X[0:20000]\n",
    "y = y[0:20000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# X_test, X_validation, y_test, y_validation = train_test_split(X_test_validation, y_test_validation, test_size=0.25, random_state=999)\n",
    "\n",
    "(samples, features, frames) = X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scaler = RobustScaler(quantile_range=(scaler_q_min, scaler_q_max))\n",
    "# X_transposed = X_train.transpose(0,2,1)\n",
    "# arr = np.reshape(X_transposed, (samples * frames, features))\n",
    "# scaled = scaler.fit_transform(arr)\n",
    "\n",
    "# pca = PCA(n_components=pca_components)\n",
    "# reduced_X = pca.fit(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_X = np.empty((samples, frames, pca_components))\n",
    "\n",
    "# for i in range(samples):\n",
    "#     flat_X[i] = pca.transform(scaler.transform(X_transposed[i]))\n",
    "\n",
    "# flat_X = np.reshape(flat_X, (samples, frames * pca_components))\n",
    "# print(flat_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC(cache_size=1000, verbose=True, class_weight='balanced', C = svm_cost, kernel=svm_kernel)\n",
    "# clf.fit(flat_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (samples, features, frames) = X_test.shape\n",
    "\n",
    "# X_test_transposed = X_test.transpose(0,2,1)\n",
    "# arr = np.reshape(X_test_transposed, (samples * frames, features))\n",
    "# scaled = scaler.transform(arr)\n",
    "\n",
    "# reduced_X_test = pca.transform(scaled)\n",
    "\n",
    "# flat_X_test = np.empty((samples, frames, pca_components))\n",
    "\n",
    "# for i in range(samples):\n",
    "#     flat_X_test[i] = pca.transform(scaler.transform(X_test_transposed[i]))\n",
    "\n",
    "# flat_X_test = np.reshape(flat_X_test, (samples, frames * pca_components))\n",
    "# print(flat_X_test.shape)\n",
    "\n",
    "# y_pred = clf.predict(flat_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test[0:10])\n",
    "# print(y_pred[0:10])\n",
    "# print(np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_pred, labels=np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes.CLASSES)\n",
    "# disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skopt import BayesSearchCV\n",
    "import json\n",
    "\n",
    "\n",
    "class SVMClassifier(BaseEstimator):\n",
    "     def __init__(self, pca_components = chosen_pca_components, svm_cost = chosen_svm_cost, svm_kernel = chosen_svm_kernel, scaler_q = chosen_scaler_q):\n",
    "          self.pca_components = pca_components \n",
    "          self.svm_cost = svm_cost \n",
    "          self.svm_kernel = svm_kernel\n",
    "          self.scaler_q = scaler_q\n",
    "\n",
    "          self.clf = None\n",
    "          self.scaler = None\n",
    "          self.pca = None\n",
    "\n",
    "     def fit(self, X, y):\n",
    "\n",
    "          (samples, features, frames) = X.shape\n",
    "\n",
    "          scaler_q_min = self.scaler_q \n",
    "          scaler_q_max = 100 - self.scaler_q\n",
    "\n",
    "          self.scaler = RobustScaler(quantile_range=(scaler_q_min, scaler_q_max))\n",
    "          X_transposed = X.transpose(0,2,1)\n",
    "          arr = np.reshape(X_transposed, (samples * frames, features))\n",
    "          scaled = self.scaler.fit_transform(arr)\n",
    "\n",
    "          self.pca = PCA(n_components=self.pca_components)\n",
    "          reduced_X = self.pca.fit(scaled)\n",
    "\n",
    "          flat_X = np.empty((samples, frames, self.pca_components))\n",
    "\n",
    "          for i in range(samples):\n",
    "               flat_X[i] = self.pca.transform(self.scaler.transform(X_transposed[i]))\n",
    "\n",
    "          flat_X = np.reshape(flat_X, (samples, frames * self.pca_components))\n",
    "\n",
    "          self.clf = svm.SVC(cache_size=1000, class_weight='balanced', C = self.svm_cost, kernel=self.svm_kernel)\n",
    "          self.clf.fit(flat_X, y)\n",
    "\n",
    "          self.is_fitted_ = True\n",
    "          return self\n",
    "\n",
    "     def predict(self, X):\n",
    "\n",
    "          if not self.is_fitted_:\n",
    "               raise Exception(\"Not fitted\")\n",
    "\n",
    "          (samples, features, frames) = X.shape\n",
    "\n",
    "          X_test_transposed = X.transpose(0,2,1)\n",
    "          arr = np.reshape(X_test_transposed, (samples * frames, features))\n",
    "          scaled = self.scaler.transform(arr)\n",
    "\n",
    "\n",
    "          flat_X_test = np.empty((samples, frames, self.pca_components))\n",
    "\n",
    "          for i in range(samples):\n",
    "               flat_X_test[i] = self.pca.transform(self.scaler.transform(X_test_transposed[i]))\n",
    "\n",
    "          flat_X_test = np.reshape(flat_X_test, (samples, frames * self.pca_components))\n",
    "\n",
    "          y_pred = self.clf.predict(flat_X_test)\n",
    "\n",
    "          return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVMClassifier()\n",
    "# clf.fit(X,y)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'svm_cost': [0.5, 1, 5, 10], \n",
    "    \"pca_components\": [7, 10, 15],\n",
    "    \"svm_kernel\": [\"poly\", \"rbf\"],\n",
    "    \"scaler_q\": [25, 15, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE = False\n",
    "NORMAL_RUN = False\n",
    "\n",
    "clf = None\n",
    "\n",
    "if OPTIMIZE:\n",
    "    estimator = SVMClassifier()\n",
    "    bayes = BayesSearchCV(estimator, parameters, n_iter=20, n_jobs=1,scoring=\"f1_weighted\", cv=ShuffleSplit(n_splits=1, test_size=0.2))\n",
    "    bayes.fit(X_train, y_train)\n",
    "\n",
    "    clf = SVMClassifier(**bayes.best_params_)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "elif NORMAL_RUN:\n",
    "    clf = SVMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "if clf:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = str(f1_score(y_test, y_pred, average='micro'))\n",
    "    accuracy = str(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(f1, accuracy, clf.get_params())\n",
    "\n",
    "    with open('svm_params.txt', 'w') as file:\n",
    "        file.write(accuracy)\n",
    "        file.write(\"\\n\")\n",
    "        file.write(f1)\n",
    "        file.write(\"\\n\")\n",
    "        file.write(json.dumps(clf.get_params()))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes.CLASSES)\n",
    "    disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERFITTING = True\n",
    "\n",
    "if OVERFITTING:\n",
    "    accuracies = []\n",
    "\n",
    "    for cost in [0.5,1,5,10,20,40,80]:\n",
    "        clf = SVMClassifier(svm_cost=cost)\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        accuracy_train = str(accuracy_score(y_train, y_pred_train))\n",
    "        accuracy_test = str(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "        print(accuracy_train, accuracy_test)\n",
    "    \n",
    "        accuracies.append((accuracy_train, accuracy_test))\n",
    "\n",
    "    print(accuracies)\n",
    "\n",
    "\n",
    "# [1,5,10,20,40,80]\n",
    "# [('0.8222941176470588', '0.832'), ('0.9428823529411765', '0.9453333333333334'), ('0.974', '0.9753333333333334'), ('0.9888823529411764', '0.9903333333333333'), ('0.9972352941176471', '0.9986666666666667'), ('0.9997647058823529', '1.0')]\n",
    "\n",
    "# [0.5, 160, 320]\n",
    "# [('0.7744705882352941', '0.7903333333333333'), ('1.0', '1.0'), ('1.0', '1.0')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
