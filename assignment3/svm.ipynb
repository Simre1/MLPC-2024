{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../libs')  # Update this path according to the location of your 'dataset' module\n",
    "import dataset\n",
    "import preprocessing\n",
    "import classes\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen Hyper Params\n",
    "\n",
    "pca_components = 10\n",
    "svm_cost = 1\n",
    "svm_kernel = \"poly\"\n",
    "scaler_q_min = 25\n",
    "scaler_q_max = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data()\n",
    "y = np.array(list(map(classes.label_to_class, dataset.labels_array())))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# X_test, X_validation, y_test, y_validation = train_test_split(X_test_validation, y_test_validation, test_size=0.25, random_state=999)\n",
    "\n",
    "(samples, features, frames) = X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scaler = RobustScaler(quantile_range=(scaler_q_min, scaler_q_max))\n",
    "# X_transposed = X_train.transpose(0,2,1)\n",
    "# arr = np.reshape(X_transposed, (samples * frames, features))\n",
    "# scaled = scaler.fit_transform(arr)\n",
    "\n",
    "# pca = PCA(n_components=pca_components)\n",
    "# reduced_X = pca.fit(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_X = np.empty((samples, frames, pca_components))\n",
    "\n",
    "# for i in range(samples):\n",
    "#     flat_X[i] = pca.transform(scaler.transform(X_transposed[i]))\n",
    "\n",
    "# flat_X = np.reshape(flat_X, (samples, frames * pca_components))\n",
    "# print(flat_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC(cache_size=1000, verbose=True, class_weight='balanced', C = svm_cost, kernel=svm_kernel)\n",
    "# clf.fit(flat_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (samples, features, frames) = X_test.shape\n",
    "\n",
    "# X_test_transposed = X_test.transpose(0,2,1)\n",
    "# arr = np.reshape(X_test_transposed, (samples * frames, features))\n",
    "# scaled = scaler.transform(arr)\n",
    "\n",
    "# reduced_X_test = pca.transform(scaled)\n",
    "\n",
    "# flat_X_test = np.empty((samples, frames, pca_components))\n",
    "\n",
    "# for i in range(samples):\n",
    "#     flat_X_test[i] = pca.transform(scaler.transform(X_test_transposed[i]))\n",
    "\n",
    "# flat_X_test = np.reshape(flat_X_test, (samples, frames * pca_components))\n",
    "# print(flat_X_test.shape)\n",
    "\n",
    "# y_pred = clf.predict(flat_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test[0:10])\n",
    "# print(y_pred[0:10])\n",
    "# print(np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_pred, labels=np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes.CLASSES)\n",
    "# disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "class SVMClassifier(BaseEstimator):\n",
    "     def __init__(self, pca_components = 10, svm_cost = 1, svm_kernel = \"poly\", scaler_q = 25):\n",
    "          self.pca_components = pca_components \n",
    "          self.svm_cost = svm_cost \n",
    "          self.svm_kernel = svm_kernel\n",
    "          self.scaler_q = scaler_q\n",
    "\n",
    "          self.clf = None\n",
    "          self.scaler = None\n",
    "          self.pca = None\n",
    "\n",
    "     def fit(self, X, y):\n",
    "\n",
    "          print(\"Fitting now\", X.shape)\n",
    "          (samples, features, frames) = X.shape\n",
    "\n",
    "          scaler_q_min = self.scaler_q \n",
    "          scaler_q_max = 100 - self.scaler_q\n",
    "\n",
    "          self.scaler = RobustScaler(quantile_range=(scaler_q_min, scaler_q_max))\n",
    "          X_transposed = X.transpose(0,2,1)\n",
    "          arr = np.reshape(X_transposed, (samples * frames, features))\n",
    "          scaled = self.scaler.fit_transform(arr)\n",
    "\n",
    "          self.pca = PCA(n_components=self.pca_components)\n",
    "          reduced_X = self.pca.fit(scaled)\n",
    "\n",
    "          flat_X = np.empty((samples, frames, self.pca_components))\n",
    "\n",
    "          for i in range(samples):\n",
    "               flat_X[i] = self.pca.transform(self.scaler.transform(X_transposed[i]))\n",
    "\n",
    "          flat_X = np.reshape(flat_X, (samples, frames * self.pca_components))\n",
    "\n",
    "          self.clf = svm.SVC(cache_size=1000, verbose=True, class_weight='balanced', C = self.svm_cost, kernel=self.svm_kernel)\n",
    "          self.clf.fit(flat_X, y)\n",
    "\n",
    "          self.is_fitted_ = True\n",
    "          return self\n",
    "\n",
    "     def predict(self, X):\n",
    "\n",
    "          if not self.is_fitted_:\n",
    "               raise Exception(\"Not fitted\")\n",
    "\n",
    "          (samples, features, frames) = X.shape\n",
    "\n",
    "          X_test_transposed = X.transpose(0,2,1)\n",
    "          arr = np.reshape(X_test_transposed, (samples * frames, features))\n",
    "          scaled = self.scaler.transform(arr)\n",
    "\n",
    "          flat_X_test = np.empty((samples, frames, pca_components))\n",
    "\n",
    "          for i in range(samples):\n",
    "               flat_X_test[i] = self.pca.transform(self.scaler.transform(X_test_transposed[i]))\n",
    "\n",
    "          flat_X_test = np.reshape(flat_X_test, (samples, frames * pca_components))\n",
    "\n",
    "          y_pred = clf.predict(flat_X_test)\n",
    "\n",
    "          return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVMClassifier()\n",
    "# clf.fit(X,y)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'svm_cost': [0.5, 1, 5], \n",
    "    \"pca_components\": [7, 10, 15],\n",
    "    \"svm_kernel\": [\"poly\", \"rbf\"],\n",
    "    \"scaler_q\": [25, 15, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n",
      "Fitting now (30800, 175, 44)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/simon/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_2107/4154501050.py\", line 37, in fit\n    flat_X[i] = self.pca.transform(scaler.transform(X_transposed[i]))\n                                   ^^^^^^\nNameError: name 'scaler' is not defined. Did you mean: 'self.scaler'?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/simon/Studium/Master5/Patterns/MLPC-2024/assignment3/svm.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/simon/Studium/Master5/Patterns/MLPC-2024/assignment3/svm.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m estimator \u001b[39m=\u001b[39m SVMClassifier()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/simon/Studium/Master5/Patterns/MLPC-2024/assignment3/svm.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomizedSearchCV(estimator, parameters, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mf1_weighted\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cv\u001b[39m=\u001b[39mShuffleSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/simon/Studium/Master5/Patterns/MLPC-2024/assignment3/svm.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    972\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1913\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1915\u001b[0m         ParameterSampler(\n\u001b[1;32m   1916\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1917\u001b[0m         )\n\u001b[1;32m   1918\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    941\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 947\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    949\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/simon/.conda/envs/mlpc-2024/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_2107/4154501050.py\", line 37, in fit\n    flat_X[i] = self.pca.transform(scaler.transform(X_transposed[i]))\n                                   ^^^^^^\nNameError: name 'scaler' is not defined. Did you mean: 'self.scaler'?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator = SVMClassifier()\n",
    "\n",
    "clf = RandomizedSearchCV(estimator, parameters, n_iter=10, n_jobs=1,scoring=\"f1_weighted\", verbose=True, cv=ShuffleSplit(n_splits=1, test_size=0.2))\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=np.array(list(classes.REVERSE_CLASSES.keys())))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes.CLASSES)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
