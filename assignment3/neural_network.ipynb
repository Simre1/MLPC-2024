{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23de171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../libs')  # Update this path according to the location of your 'dataset' module\n",
    "import dataset\n",
    "import preprocessing\n",
    "import classes\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.extmath import weighted_mode\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import random\n",
    "\n",
    "from timeit import default_timer as timer \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchmetrics, mlxtend\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0955498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "#PROJECT_PATH = pathlib.Path(__file__).parent.parent.resolve()\n",
    "DEVELOPMENT_FILE = \"../Files/metadata/development.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdffb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fd7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0725c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595be83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming dataset.data() returns your numpy array and classes.label_to_class converts labels to classes\n",
    "X = dataset.data()\n",
    "y = np.array(list(map(classes.label_to_class, dataset.labels_array())))\n",
    "\n",
    "# Take only the melspect feature\n",
    "X_new = X[:, 12:76, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d3a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a DataFrame (replace this with your data loading code)\n",
    "data = pd.read_csv(DEVELOPMENT_FILE)\n",
    "\n",
    "# Get unique speaker IDs\n",
    "speaker_ids = data['speaker_id'].unique()\n",
    "\n",
    "# Split speaker IDs into train, test, and dev sets\n",
    "train_speaker_ids, test_dev_speaker_ids = train_test_split(speaker_ids, test_size=0.2, random_state=42)\n",
    "test_speaker_ids, dev_speaker_ids = train_test_split(test_dev_speaker_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "# Filter data into train, test, and dev sets based on speaker IDs\n",
    "train_data = data[data['speaker_id'].isin(train_speaker_ids)]\n",
    "test_data = data[data['speaker_id'].isin(test_speaker_ids)]\n",
    "dev_data = data[data['speaker_id'].isin(dev_speaker_ids)]\n",
    "\n",
    "# Optionally, shuffle the train, test, and dev DataFrames\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "dev_data = dev_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cea8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample specific words in the training data\n",
    "words_to_oversample = ['Alarm', 'aus', 'offen']  # List of words to oversample\n",
    "oversampled_data = pd.concat([resample(train_data[train_data['word'].isin(words_to_oversample)], \n",
    "                                       replace=True,  # With replacement\n",
    "                                       n_samples=3000,  # Adjust oversampling size as needed\n",
    "                                       random_state=42),  # Set random state for reproducibility\n",
    "                              train_data])\n",
    "\n",
    "# Shuffle the oversampled data\n",
    "oversampled_data = oversampled_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254886d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of rows corresponding to speaker IDs in train, test, and dev sets\n",
    "# train_indices = train_data['id'].values\n",
    "# Get the indices of rows corresponding to speaker IDs in train, test, and dev sets\n",
    "train_indices = oversampled_data['id'].values\n",
    "test_indices = test_data['id'].values\n",
    "dev_indices = dev_data['id'].values\n",
    "\n",
    "# Select the corresponding columns of X for train, test, and dev sets\n",
    "X_train = X_new[train_indices, :, :]\n",
    "X_test = X_new[test_indices, :, :]\n",
    "X_dev = X_new[dev_indices, :, :]\n",
    "\n",
    "# Split labels (y) along with features (X)\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "y_dev = y[dev_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd028faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other          3520\n",
      "offen          2651\n",
      "Alarm          2608\n",
      "aus            2603\n",
      "Schraube       1627\n",
      "Fernseher      1626\n",
      "Lüftung        1626\n",
      "Leitung        1626\n",
      "nicht          1625\n",
      "Ofen           1624\n",
      "wunderbar      1624\n",
      "Licht          1624\n",
      "Radio          1622\n",
      "Haus           1622\n",
      "an             1621\n",
      "kann           1620\n",
      "Brötchen       1620\n",
      "Spiegel        1620\n",
      "warm           1620\n",
      "Staubsauger    1619\n",
      "Heizung        1618\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if oversampling worked as expected\n",
    "print(oversampled_data['word'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a6d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (38966, 64, 44)\n",
      "Test set shape: (4571, 64, 44)\n",
      "Validation set shape: (4759, 64, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Validation set shape:\", X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6876659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are numpy arrays\n",
    "# Convert them to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_dev_tensor = torch.tensor(X_dev, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # y_train contains integer labels\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)    # y_test contains integer labels\n",
    "y_dev_tensor = torch.tensor(y_dev, dtype=torch.long)    # y_dev contains integer labels\n",
    "\n",
    "X_train_tensor = X_train_tensor.unsqueeze(dim=1)\n",
    "X_test_tensor = X_test_tensor.unsqueeze(dim=1)\n",
    "X_dev_tensor = X_dev_tensor.unsqueeze(dim=1)\n",
    "\n",
    "# Create training and test datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "dev_dataset = TensorDataset(X_dev_tensor, y_dev_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9819762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataloader: 1217 batches of 32\n",
      "Length of test dataloader: 142 batches of 32\n",
      "Length of dev dataloader: 148 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_dataset, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    drop_last=True,\n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    drop_last=True,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of dev dataloader: {len(dev_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "584d158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioClassifierCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Reshape the tensor to have a two-dimensional shape\n",
    "        x = x.view(-1, 128 * 4 * 2)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f916f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()  # Accumulate the loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))  # Accumulate the accuracy\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(data_loader, model, loss_fn, accuracy_fn, device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Turn off gradient computation\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()  # Accumulate the loss\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))  # Accumulate the accuracy\n",
    "\n",
    "        # Calculate loss and accuracy per epoch and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ab8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = AudioClassifierCNN(len(classes.CLASSES))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0716e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84b4146bd374d47b9b30cf667c4898e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.69435 | Train accuracy: 77.96%\n",
      "Test loss: 0.43513 | Test accuracy: 85.89%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "train_time_start_model = timer()\n",
    "\n",
    "delta = 1e-2\n",
    "patience = 3\n",
    "best_test_loss = float('inf')\n",
    "best_epoch = 0\n",
    "counter = 0\n",
    "    \n",
    "# Train and test model \n",
    "epochs = 20\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    \n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if test_loss < best_test_loss - delta:\n",
    "        best_test_loss = test_loss\n",
    "        best_epoch = epoch\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping. No improvement since epoch {best_epoch}.')\n",
    "            break\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions with trained model\n",
    "y_preds = []\n",
    "y_true = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(dev_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_true.append(y)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "y_true_tensor = torch.cat(y_true).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac500cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(num_classes=len(classes.CLASSES), task='multiclass')\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=y_true_tensor)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy \n",
    "    class_names=classes.CLASSES, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea9687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
